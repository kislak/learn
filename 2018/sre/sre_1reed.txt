- Introduction

tenets of sre

SRE team is responsible for the
  availability,
  latency,
  performance,
  efficiency,
  change management,
  monitoring,
  emergency response,
  capacity planning

conduct a postmortem
blame-free postmortem culture

Pursuing Maximum Change Velocity Without Violating a Service’s SLO

There are three kinds of valid monitoring output:
alert
ticket
logging

Reliability is a function of mean time to failure (MTTF) and mean time to repair (MTTR)
  R = mttf/mttr

machine - rack - row - cluster - datacenter - campus
borg - distributed cluster operating system
bns - borg name service (name ->  ip:port)
hdfs - Hadoop Distributed File System
Google File System -> Colossus (BigTable, Spanner, Blobstore)
Global Software Load Balancer (GSLB)
  dns
  service
  RPC
// name, {BNS list -> capacity (RPS)}

The Chubby lock service provides - Paxos protocol for asynchronous Consensus

monitoring:
Set up alerting for acute problems.
Compare behavior: did a software update make the server faster?
Examine how resource consumption behavior evolves over time, which is essential for capacity planning.
Stubby - gRPC

- Principles
- 3 Embracing risk (принять(охватывать, видеть) риски)

99% - availability
availability = uptime/update+downtime
availability = 200/404

types of error effects (sign up vs 1 feature)

cost vs profit
  if we were to build +9 in availability
    what would incremental increase in revenue be?

falling between 0.01% and 1%

error budget

Hope is not a strategy

- 4 Service Level Objectives
SLI
  what user want (from intuition)
  quantitative measure of some aspect of the level of service

  request latency
  error rate
  system throughput
  availability
  durability (storage)
  correctness

- 5 Eliminating Toil
  operational work = toil
  Manual
  Repetitive
  Automatable
  Tactical
  No enduring value
  O(n) with service growth

  invent more, toil less.

- 6 Monitoring Distributed Systems
  monitoring
    Collecting, processing, aggregating, and displaying real-time quantitative data about a system
  White-box monitoring
  Black-box monitoring
  Dashboard
  Alert
  Root cause
  Node and machine
  Push
    any change


  monitor
    analyze long-term trends
    comparing(time/group)
    alerting
    building dashboards
    Conducting ad hoc retrospective analysis (i.e., debugging)

The four golden signals of monitoring are
 latency,
 traffic,
 errors,
 saturation (memory, i/o, cpu)

To remedy the situation, the team used a three-pronged approach

- 7 The Evolution of Automation at Google
